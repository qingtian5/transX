{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b989aaf2-09ae-4c88-a640-bbcad05f60b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 11:21:19,689 - preprocessor.py[line:145] - INFO: check up output dir and clear dir: /root/autodl-tmp/transX/output/TransD\n",
      "2024-03-26 11:21:19,691 - 3684119019.py[line:100] - INFO: available device: cuda:0，count_gpu: 1\n",
      "2024-03-26 11:21:19,767 - 3684119019.py[line:124] - INFO: ************** Running training ****************\n",
      "2024-03-26 11:21:19,768 - 3684119019.py[line:125] - INFO: Num Examples = 9911\n",
      "2024-03-26 11:21:19,769 - 3684119019.py[line:126] - INFO: Num Epochs = 1\n",
      "2024-03-26 11:21:19,770 - 3684119019.py[line:127] - INFO: Num Seed = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is model on gpu:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Iteration:   0%|          | 0/78 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:   1%|▏         | 1/78 [00:00<00:17,  4.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:   5%|▌         | 4/78 [00:00<00:05, 13.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:   9%|▉         | 7/78 [00:00<00:03, 17.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  13%|█▎        | 10/78 [00:00<00:03, 20.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  17%|█▋        | 13/78 [00:00<00:02, 22.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  21%|██        | 16/78 [00:00<00:02, 23.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  24%|██▍       | 19/78 [00:00<00:02, 24.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  28%|██▊       | 22/78 [00:01<00:02, 25.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  32%|███▏      | 25/78 [00:01<00:02, 25.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  36%|███▌      | 28/78 [00:01<00:02, 20.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  41%|████      | 32/78 [00:01<00:01, 23.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  46%|████▌     | 36/78 [00:01<00:01, 25.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  51%|█████▏    | 40/78 [00:01<00:01, 27.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  56%|█████▋    | 44/78 [00:01<00:01, 28.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  62%|██████▏   | 48/78 [00:02<00:01, 29.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  67%|██████▋   | 52/78 [00:02<00:00, 29.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  72%|███████▏  | 56/78 [00:02<00:00, 30.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  77%|███████▋  | 60/78 [00:02<00:00, 30.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  82%|████████▏ | 64/78 [00:02<00:00, 30.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  87%|████████▋ | 68/78 [00:02<00:00, 30.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration:  92%|█████████▏| 72/78 [00:02<00:00, 30.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Iteration: 100%|██████████| 78/78 [00:02<00:00, 26.47it/s]\u001b[A\u001b[A\n",
      "2024-03-26 11:21:22,750 - 3684119019.py[line:160] - INFO: Seed: 0, epoch: 0, iteration is finished, the min_loss is 4.681209564208984\n",
      "2024-03-26 11:21:22,752 - 3684119019.py[line:166] - INFO: ********* Running eval start **********\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:01,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:02,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:03,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "5it [00:04,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "6it [00:05,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "7it [00:06,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "8it [00:07,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "9it [00:08,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "10it [00:08,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "11it [00:09,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "12it [00:10,  1.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "13it [00:11,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "14it [00:12,  1.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "15it [00:13,  1.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "16it [00:14,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "17it [00:15,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "18it [00:16,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "19it [00:17,  1.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "20it [00:18,  1.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "21it [00:19,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "22it [00:20,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "23it [00:20,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "24it [00:21,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "25it [00:22,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "26it [00:23,  1.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "27it [00:24,  1.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "28it [00:25,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "29it [00:26,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "30it [00:27,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "31it [00:28,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "32it [00:29,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "33it [00:29,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "34it [00:30,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "35it [00:31,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "36it [00:32,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "37it [00:33,  1.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "38it [00:34,  1.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "39it [00:35,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "40it [00:36,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "41it [00:37,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "42it [00:38,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "43it [00:38,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "44it [00:39,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "45it [00:40,  1.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "46it [00:41,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "47it [00:42,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "48it [00:43,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "49it [00:44,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "50it [00:45,  1.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "51it [00:46,  1.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "52it [00:47,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "53it [00:48,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "54it [00:49,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "55it [00:49,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "56it [00:50,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "57it [00:51,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "58it [00:52,  1.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "59it [00:53,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "60it [00:54,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "61it [00:55,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "62it [00:56,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "63it [00:57,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "64it [00:58,  1.10it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @description: \n",
    "# @author: zchen\n",
    "# @time: 2020/12/9 20:47\n",
    "# @file: main.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from annoy import AnnoyIndex\n",
    "from torch.autograd import Variable\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "import evaluation\n",
    "from config import Config\n",
    "from logger import logger\n",
    "from models.KG2E import KG2E\n",
    "from models.TransA import TransA\n",
    "from models.TransD import TransD\n",
    "from models.TransE import TransE\n",
    "from models.TransH import TransH\n",
    "from preprocessor import TransXProcessor\n",
    "from utils import save_json_file, calculate_distance\n",
    "\n",
    "\n",
    "class TransX(object):\n",
    "    def __init__(self):\n",
    "        self.processor = TransXProcessor()\n",
    "        self.config = Config()\n",
    "        if self.config.getTxt:\n",
    "            TransXProcessor.generate_data(config=self.config)\n",
    "        self.entity_dict, self.relation_dict = self.processor.init_data_dict(config=self.config)\n",
    "        self.id2entity = {v: k for k, v in self.entity_dict.items()}\n",
    "        self.entity_num, self.relation_num = len(self.entity_dict.keys()), len(self.relation_dict.keys())\n",
    "\n",
    "    def _init_model(self):\n",
    "        \"\"\"\n",
    "        根据配置项model_name,初始化对应的模型\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if self.config.model_name == \"TransE\":\n",
    "            model = TransE(entity_num=self.entity_num,\n",
    "                           relation_num=self.relation_num,\n",
    "                           embedding_dim=self.config.TransE[\"EmbeddingDim\"],\n",
    "                           margin=self.config.TransE[\"Margin\"])\n",
    "        elif self.config.model_name == \"TransH\":\n",
    "            model = TransH(entity_num=self.entity_num,\n",
    "                           relation_num=self.relation_num,\n",
    "                           embedding_dim=self.config.TransH[\"EmbeddingDim\"],\n",
    "                           margin=self.config.TransH[\"Margin\"],\n",
    "                           C=self.config.TransH[\"C\"],\n",
    "                           eps=self.config.TransH[\"Eps\"])\n",
    "        elif self.config.model_name == \"TransA\":\n",
    "            model = TransA(entity_num=self.entity_num,\n",
    "                           relation_num=self.relation_num,\n",
    "                           embedding_dim=self.config.TransA[\"EmbeddingDim\"],\n",
    "                           margin=self.config.TransA[\"Margin\"],\n",
    "                           lamb=self.config.TransA[\"Lamb\"],\n",
    "                           C=self.config.TransA[\"C\"])\n",
    "        elif self.config.model_name == \"TransD\":\n",
    "            model = TransD(entity_num=self.entity_num,\n",
    "                           relation_num=self.relation_num,\n",
    "                           entity_dim=self.config.TransD[\"EntityDim\"],\n",
    "                           relation_dim=self.config.TransD[\"RelationDim\"],\n",
    "                           margin=self.config.TransD[\"Margin\"])\n",
    "        elif self.config.model_name == \"KG2E\":\n",
    "            model = KG2E(entity_num=self.entity_num,\n",
    "                         relation_num=self.relation_num,\n",
    "                         embedding_dim=self.config.KG2E[\"EmbeddingDim\"],\n",
    "                         margin=self.config.KG2E[\"Margin\"],\n",
    "                         sim=self.config.KG2E[\"Sim\"],\n",
    "                         vmin=self.config.KG2E[\"Vmin\"],\n",
    "                         vmax=self.config.KG2E[\"Vmax\"])\n",
    "        else:\n",
    "            model = None\n",
    "            print(\"ERROR : No model named %s\" % self.config.model_name)\n",
    "            exit(1)\n",
    "\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def adjust_learning_rate(optimizer, decay):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] *= decay\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        模型训练\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 对输出目录进行初始化操作,当output存在,则删除\n",
    "        self.processor.clean_output(self.config)\n",
    "\n",
    "        use_gpu = self.config.use_gpu and torch.cuda.is_available()\n",
    "        device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "        logger.info(\"available device: {}，count_gpu: {}\".format(device, torch.cuda.device_count()))\n",
    "\n",
    "        # 获取eval数据集以及对应的data_loader\n",
    "        eval_data_set = self.processor.data_set(config=self.config, entity_dict=self.entity_dict,\n",
    "                                                relation_dict=self.relation_dict, mode=\"eval\")\n",
    "        eval_data_loader = self.processor.data_loader(config=self.config, data_set=eval_data_set, mode=\"eval\")\n",
    "\n",
    "        # 获取训练数据集\n",
    "        train_data_set = self.processor.data_set(config=self.config, entity_dict=self.entity_dict,\n",
    "                                                 relation_dict=self.relation_dict, mode=\"train\")\n",
    "        # 初始化模型\n",
    "        model = self._init_model()\n",
    "        if model:\n",
    "            model.to(device)\n",
    "\n",
    "            \n",
    "        print('Is model on gpu: ', next(model.parameters()).is_cuda)\n",
    "        if self.config.do_train:\n",
    "            min_loss, best_mr = float(\"inf\"), float(\"inf\")\n",
    "\n",
    "            # 优化器\n",
    "            optimizer = torch.optim.Adam(model.parameters(), weight_decay=self.config.weight_decay,\n",
    "                                         lr=self.config.learning_rate)\n",
    "\n",
    "            logger.info(\"************** Running training ****************\")\n",
    "            logger.info(\"Num Examples = {}\".format(len(train_data_set)))\n",
    "            logger.info(\"Num Epochs = {}\".format(int(self.config.epochs)))\n",
    "            logger.info(\"Num Seed = {}\".format(self.config.seed))\n",
    "\n",
    "            for seed in trange(int(self.config.seed), desc=\"Seed\"):\n",
    "                train_data_loader = self.processor.data_loader(config=self.config, data_set=train_data_set,\n",
    "                                                               mode=\"train\")\n",
    "\n",
    "                for epoch in trange(int(self.config.epochs), desc=\"Epoch\"):\n",
    "\n",
    "                    for step, batch in enumerate(tqdm(train_data_loader, desc=\"Iteration\")):\n",
    "                        posX, negX = batch\n",
    "                        if use_gpu:\n",
    "                            posX = Variable(posX.to(device))\n",
    "                            negX = Variable(negX.to(device))\n",
    "                        else:\n",
    "                            posX = Variable(posX)\n",
    "                            negX = Variable(negX)\n",
    "\n",
    "                        # Normalize the embedding if neccessary\n",
    "                        model.normalize_embedding()\n",
    "\n",
    "                        # Calculate the loss from the model\n",
    "                        loss = model(posX, negX)\n",
    "                        loss_val = loss.item()\n",
    "\n",
    "                        # Calculate the gradient and step down\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        # Print infomation and add to summary\n",
    "                        if min_loss > loss_val:\n",
    "                            min_loss = loss_val\n",
    "\n",
    "                    logger.info(f\"Seed: {seed}, epoch: {epoch}, iteration is finished, the min_loss is {min_loss}\")\n",
    "\n",
    "                    if (epoch + 1) % self.config.lr_decay_epoch == 0:\n",
    "                        self.adjust_learning_rate(optimizer, decay=self.config.lr_decay)\n",
    "\n",
    "                    if self.config.do_eval and (epoch + 1) % self.config.eval_epoch == 0:\n",
    "                        logger.info(\"********* Running eval start **********\")\n",
    "                        mr = evaluation.mr_evaluation(eval_loader=eval_data_loader, model=self.config.model_name,\n",
    "                                                      sim_measure=self.config.sim_measure,\n",
    "                                                      **model.ret_eval_weights())\n",
    "                        logger.info(\"running eval end... MR score is {}\".format(mr))\n",
    "\n",
    "                        if mr < best_mr:\n",
    "                            logger.info(f\"-------------the best_mr is {mr}, save model--------------\")\n",
    "                            best_mr = mr\n",
    "                            torch.save(model, os.path.join(self.config.model_path, \"kg_model.ckpt\"))\n",
    "\n",
    "            logger.info(f\"<<<<<< the global_best_mr is {best_mr}, the min_loss is {min_loss} >>>>>>\")\n",
    "            logger.info(\"train the {} model successful!!! save dir is {}\".format(self.config.model_name,\n",
    "                                                                                 self.config.model_path))\n",
    "\n",
    "            logger.info(\"start dump_embedding, save dir is {}\".format(self.config.dump_embedding_path))\n",
    "            self.dump_embedding(model)\n",
    "            logger.info(\"dump_embedding successful!!!\")\n",
    "\n",
    "            #logger.info(\"start dump_annoy_index, save index dir is {}\".format(self.config.annoy_index_path))\n",
    "            #self.dump_annoy_index(model)\n",
    "            #logger.info(\"dump_annoy_index successful!!!\")\n",
    "\n",
    "    def dump_embedding(self, load_model):\n",
    "        \"\"\"\n",
    "        向量持久化\n",
    "        :param load_model:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        ent_weight = load_model.entityEmbedding.weight.detach().cpu().numpy()\n",
    "        rel_weight = load_model.relationEmbedding.weight.detach().cpu().numpy()\n",
    "        entity_embedding_path = os.path.join(self.config.dump_embedding_path, \"entity_embedding.txt\")\n",
    "        relation_embedding_path = os.path.join(self.config.dump_embedding_path, \"relation_embedding.txt\")\n",
    "        # 保存实体向量\n",
    "        ent_embed_list = [dict(word=ent, word_vet=embed) for ent, embed in\n",
    "                          zip(self.entity_dict.keys(), ent_weight.tolist())]\n",
    "        save_json_file(ent_embed_list, entity_embedding_path)\n",
    "        # 保存关系向量\n",
    "        rel_embed_list = [dict(word=rel, word_vet=embed) for rel, embed in\n",
    "                          zip(self.relation_dict.keys(), rel_weight.tolist())]\n",
    "        save_json_file(rel_embed_list, relation_embedding_path)\n",
    "\n",
    "    def dump_annoy_index(self, load_model):\n",
    "        \"\"\"\n",
    "        构建annoy索引\n",
    "        :param load_model:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        ent_weight = load_model.entityEmbedding.weight.detach().cpu().numpy()\n",
    "        annoy_index = AnnoyIndex(100)\n",
    "        for idx, (ent, embed) in enumerate(dict(zip(self.entity_dict.keys(), ent_weight)).items()):\n",
    "            annoy_index.add_item(idx, embed)\n",
    "        annoy_index.build(200)\n",
    "        if not os.path.exists(self.config.annoy_index_path):\n",
    "            os.makedirs(self.config.annoy_index_path)\n",
    "        \n",
    "        #joblib.dump(annoy_index,os.path.join(self.config.annoy_index_path, \"annoy_index.pkl\"))\n",
    "        annoy_index.save(os.path.join(self.config.annoy_index_path, \"annoy_index.index\"))\n",
    "\n",
    "    def similarity_topk(self, key, top_k):\n",
    "        \"\"\"\n",
    "        传统方式,找到与key相似的节点\n",
    "        :param key:\n",
    "        :param top_k:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        entity_embed_dict = dict()\n",
    "        similarity_topk = dict()\n",
    "\n",
    "        with open(os.path.join(self.config.dump_embedding_path, \"entity_embedding.txt\"), \"r\",\n",
    "                  encoding=\"utf-8\") as f:\n",
    "            for line in f.readlines():\n",
    "                json_dict = json.loads(line.strip(), encoding=\"utf-8\")\n",
    "                entity_embed_dict[json_dict[\"word\"]] = np.array(json_dict[\"word_vet\"])\n",
    "\n",
    "        key_embedding = entity_embed_dict.get(key)\n",
    "        for k, v in entity_embed_dict.items():\n",
    "            if k == key:\n",
    "                similarity_topk[k] = 0\n",
    "            else:\n",
    "                distance = calculate_distance(key_embedding, v)\n",
    "                similarity_topk[k] = distance\n",
    "        similarity_topk = sorted(similarity_topk.items(), key=lambda x: x[1], reverse=True)\n",
    "        return {i[0]: i[1] for i in similarity_topk[:top_k]}\n",
    "\n",
    "    def similarity_topk_annoy(self, key, top_k):\n",
    "        \"\"\"\n",
    "        annoy方式,找到与key相似的节点\n",
    "        :param key:\n",
    "        :param top_k:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        annoy_index = AnnoyIndex(100)\n",
    "        annoy_index.load(os.path.join(self.config.annoy_index_path, \"annoy_index.index\"))\n",
    "        key_value = self.entity_dict.get(key, None)\n",
    "        if key_value:\n",
    "            res = annoy_index.get_nns_by_item(self.entity_dict[key], top_k)\n",
    "            for i in res:\n",
    "                print(self.id2entity[i])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tr = TransX()\n",
    "    tr.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cbdbdc-7e35-45f5-b13a-f6fcc9395ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
